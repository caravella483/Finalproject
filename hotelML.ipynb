{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UnitedKingdom</td>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UnitedKingdom</td>\n",
       "      <td>The room is spacious and bright The hotel is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedKingdom</td>\n",
       "      <td>Good location Set in a lovely park friendly s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reviewer_Nationality                                        Full_Review\n",
       "0              Ireland   No real complaints the hotel was great great ...\n",
       "1            Australia   Location was good and staff were ok It is cut...\n",
       "2        UnitedKingdom   Great location in nice surroundings the bar a...\n",
       "3        UnitedKingdom   The room is spacious and bright The hotel is ...\n",
       "4        UnitedKingdom   Good location Set in a lovely park friendly s..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_df = pd.read_csv(\"../Final Project/top5.csv\")\n",
    "\n",
    "hr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326115,) (326115,)\n"
     ]
    }
   ],
   "source": [
    "X = hr_df[\"Full_Review\"].values.astype(\"U\")\n",
    "y = hr_df[\"Reviewer_Nationality\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' No real complaints the hotel was great great location surroundings rooms amenities and service Two recommendations however firstly the staff upon check in are very confusing regarding deposit payments and the staff offer you upon checkout to refund your original payment and you can make a new one Bit confusing Secondly the on site restaurant is a bit lacking very well thought out and excellent quality food for anyone of a vegetarian or vegan background but even a wrap or toasted sandwich option would be great Aside from those minor minor things fantastic spot and will be back when i return to Amsterdam No Negative',\n",
       " 'Ireland')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitedKingdom            244457\n",
      "UnitedStatesofAmerica     35196\n",
      "Australia                 21540\n",
      "Ireland                   14746\n",
      "UnitedArabEmirates        10176\n",
      "Name: Reviewer_Nationality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(hr_df[\"Reviewer_Nationality\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X) # Fit the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy , confusion matrix, classification report\n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"\"\"\\nConfusion Matrix: \\n\"\"\", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"\\nAccuracy : \\n\", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"\\nClassification Report : \\n\", \n",
    "    classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy score\n",
    "def model_accuracy(y_test, y_pred): \n",
    "        return accuracy_score(y_test,y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix: \n",
      " [[  652    15    19  5739   619]\n",
      " [   97    39    22  4541   194]\n",
      " [   75     8   200  2640   472]\n",
      " [  970   209   228 77426  1823]\n",
      " [  188    10    57  6576  4799]]\n",
      "\n",
      "Accuracy : \n",
      " 77.23243323607575\n",
      "\n",
      "Classification Report : \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            Australia       0.33      0.09      0.14      7044\n",
      "              Ireland       0.14      0.01      0.02      4893\n",
      "   UnitedArabEmirates       0.38      0.06      0.10      3395\n",
      "        UnitedKingdom       0.80      0.96      0.87     80656\n",
      "UnitedStatesofAmerica       0.61      0.41      0.49     11630\n",
      "\n",
      "             accuracy                           0.77    107618\n",
      "            macro avg       0.45      0.31      0.32    107618\n",
      "         weighted avg       0.70      0.77      0.72    107618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model\n",
    "clf = MultinomialNB()\n",
    "# Model Fit\n",
    "clf.fit(X_train,y_train)\n",
    "# Model Score\n",
    "clf.score(X_test,y_test)\n",
    "# Model Prediction\n",
    "y_pred = clf.predict(X_test)\n",
    "# Model Accuracy\n",
    "cal_accuracy(y_test, y_pred)\n",
    "NB_accuracy = model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "lr = LogisticRegression(random_state= 42)\n",
    "# Model Fit\n",
    "lr = lr.fit(X_train, y_train)\n",
    "# Model Score\n",
    "lr.score(X_test, y_test)\n",
    "# Model Predict\n",
    "y_lr_predicted = lr.predict(X_test)\n",
    "# Model Accurarcy\n",
    "cal_accuracy(y_test, y_lr_predicted)\n",
    "LR_accuracy = model_accuracy(y_test, y_lr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Model\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "# Model Fit\n",
    "tree_clf = tree_clf.fit(X_train,y_train)\n",
    "# Model score\n",
    "tree_clf.score(X_test, y_test)\n",
    "# Model Predict\n",
    "y_tree_predicted = tree_clf.predict(X_test)\n",
    "# Model Accurarcy\n",
    "cal_accuracy(y_test, y_tree_predicted)\n",
    "DT_accuracy = model_accuracy(y_test, y_tree_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "# Model Fit\n",
    "rf = rf.fit(X_train, y_train)\n",
    "# Model Score\n",
    "rf.score(X_test, y_test)\n",
    "# Model Predict\n",
    "y_rf_predicted = rf.predict(X_test)\n",
    "# Model Accurarcy\n",
    "cal_accuracy(y_test, y_rf_predicted)\n",
    "RF_accuracy = model_accuracy(y_test, y_rf_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Model\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 40, 2):\n",
    "    # Knn Model\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Model Fit\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Model score\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot    \n",
    "plt.plot(range(1, 40, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 40, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Model\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 40, 2):\n",
    "    # Knn Model\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Model Fit\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Model score\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot    \n",
    "#plt.plot(range(1, 40, 2), train_scores, marker='o')\n",
    "#plt.plot(range(1, 40, 2), test_scores, marker=\"x\")\n",
    "#plt.xlabel(\"k neighbors\")\n",
    "#plt.ylabel(\"Testing accuracy Score\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 29 provides the best accuracy where the classifier starts to stablize\n",
    "# Model\n",
    "knn = KNeighborsClassifier(n_neighbors=29)\n",
    "# Model Fit\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"K= 29\")\n",
    "# Model Predict\n",
    "y_knn_predicted = knn.predict(X_test)\n",
    "# Model Accurarcy\n",
    "cal_accuracy(y_test, y_knn_predicted)\n",
    "KNN_accuracy = model_accuracy(y_test, y_knn_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
