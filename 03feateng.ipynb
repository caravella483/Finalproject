{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_df = \"Review_dataset.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path_df, 'rb') as data:\n",
    "df = pd.read_csv(\"df_more20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>We had issues with our electronic key everyda...</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Foyer was a mess Only place to relax was the ...</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Room could have done with a microwave our roo...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0            Australia   Rooms are nice but for elderly a bit difficul...   \n",
       "1            Australia   We had issues with our electronic key everyda...   \n",
       "2            Australia   it s a shame about all the construction going...   \n",
       "3            Australia   Foyer was a mess Only place to relax was the ...   \n",
       "4            Australia   Room could have done with a microwave our roo...   \n",
       "\n",
       "   Review_length  \n",
       "0            206  \n",
       "1            378  \n",
       "2            122  \n",
       "3            923  \n",
       "4            117  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Text cleaning and preparation\n",
    "# \\r and \\n\n",
    "df['Content_Parsed_1'] = df['Negative_Review'].str.replace(\"\\r\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \" when quoting text\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing the text\n",
    "df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jcaravella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jcaravella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading punkt and wordnet from NLTK\n",
    "nltk.download('punkt')\n",
    "print(\"------------------------------------------------------------\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['Content_Parsed_4']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_5'] = lemmatized_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jcaravella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Stop Words# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_length</th>\n",
       "      <th>Content_Parsed_1</th>\n",
       "      <th>Content_Parsed_2</th>\n",
       "      <th>Content_Parsed_3</th>\n",
       "      <th>Content_Parsed_4</th>\n",
       "      <th>Content_Parsed_5</th>\n",
       "      <th>Content_Parsed_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>206</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>room be nice but for elderly a bite difficult...</td>\n",
       "      <td>room  nice   elderly  bite difficult   room  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>We had issues with our electronic key everyda...</td>\n",
       "      <td>378</td>\n",
       "      <td>We had issues with our electronic key everyda...</td>\n",
       "      <td>we had issues with our electronic key everyda...</td>\n",
       "      <td>we had issues with our electronic key everyda...</td>\n",
       "      <td>we had issues with our electronic key everyda...</td>\n",
       "      <td>we have issue with our electronic key everyda...</td>\n",
       "      <td>issue   electronic key everyday  deactivate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>122</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>it s a shame about all the construction go on...</td>\n",
       "      <td>shame    construction go    look like   be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0            Australia   Rooms are nice but for elderly a bit difficul...   \n",
       "1            Australia   We had issues with our electronic key everyda...   \n",
       "2            Australia   it s a shame about all the construction going...   \n",
       "\n",
       "   Review_length                                   Content_Parsed_1  \\\n",
       "0            206   Rooms are nice but for elderly a bit difficul...   \n",
       "1            378   We had issues with our electronic key everyda...   \n",
       "2            122   it s a shame about all the construction going...   \n",
       "\n",
       "                                    Content_Parsed_2  \\\n",
       "0   rooms are nice but for elderly a bit difficul...   \n",
       "1   we had issues with our electronic key everyda...   \n",
       "2   it s a shame about all the construction going...   \n",
       "\n",
       "                                    Content_Parsed_3  \\\n",
       "0   rooms are nice but for elderly a bit difficul...   \n",
       "1   we had issues with our electronic key everyda...   \n",
       "2   it s a shame about all the construction going...   \n",
       "\n",
       "                                    Content_Parsed_4  \\\n",
       "0   rooms are nice but for elderly a bit difficul...   \n",
       "1   we had issues with our electronic key everyda...   \n",
       "2   it s a shame about all the construction going...   \n",
       "\n",
       "                                    Content_Parsed_5  \\\n",
       "0   room be nice but for elderly a bite difficult...   \n",
       "1   we have issue with our electronic key everyda...   \n",
       "2   it s a shame about all the construction go on...   \n",
       "\n",
       "                                    Content_Parsed_6  \n",
       "0   room  nice   elderly  bite difficult   room  ...  \n",
       "1     issue   electronic key everyday  deactivate...  \n",
       "2      shame    construction go    look like   be...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Content_Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>room  nice   elderly  bite difficult   room  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>We had issues with our electronic key everyda...</td>\n",
       "      <td>issue   electronic key everyday  deactivate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>shame    construction go    look like   be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Foyer was a mess Only place to relax was the ...</td>\n",
       "      <td>foyer   mess  place  relax   bar     comforta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Room could have done with a microwave our roo...</td>\n",
       "      <td>room could     microwave  room   small leak  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0            Australia   Rooms are nice but for elderly a bit difficul...   \n",
       "1            Australia   We had issues with our electronic key everyda...   \n",
       "2            Australia   it s a shame about all the construction going...   \n",
       "3            Australia   Foyer was a mess Only place to relax was the ...   \n",
       "4            Australia   Room could have done with a microwave our roo...   \n",
       "\n",
       "                                      Content_Parsed  \n",
       "0   room  nice   elderly  bite difficult   room  ...  \n",
       "1     issue   electronic key everyday  deactivate...  \n",
       "2      shame    construction go    look like   be...  \n",
       "3   foyer   mess  place  relax   bar     comforta...  \n",
       "4   room could     microwave  room   small leak  ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_columns = [\"Reviewer_Nationality\", \"Negative_Review\", \"Content_Parsed_6\"]\n",
    "df = df[list_columns]\n",
    "df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2. Label coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {\n",
    "    'Australia': 0,\n",
    "    'Canada': 1, \n",
    " 'Germany': 2, \n",
    " 'Ireland': 3,\n",
    " 'Netherlands': 4, \n",
    " 'Saudi Arabia': 5,\n",
    " 'Switzerland': 6, \n",
    " 'United Arab Emirates': 7,\n",
    " 'United Kingdom': 8,\n",
    " 'United States of America': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category mapping\n",
    "df['Category_Code'] = df['Reviewer_Nationality']\n",
    "df = df.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>room  nice   elderly  bite difficult   room  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>We had issues with our electronic key everyda...</td>\n",
       "      <td>issue   electronic key everyday  deactivate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>shame    construction go    look like   be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Foyer was a mess Only place to relax was the ...</td>\n",
       "      <td>foyer   mess  place  relax   bar     comforta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Room could have done with a microwave our roo...</td>\n",
       "      <td>room could     microwave  room   small leak  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0            Australia   Rooms are nice but for elderly a bit difficul...   \n",
       "1            Australia   We had issues with our electronic key everyda...   \n",
       "2            Australia   it s a shame about all the construction going...   \n",
       "3            Australia   Foyer was a mess Only place to relax was the ...   \n",
       "4            Australia   Room could have done with a microwave our roo...   \n",
       "\n",
       "                                      Content_Parsed Category_Code  \n",
       "0   room  nice   elderly  bite difficult   room  ...             0  \n",
       "1     issue   electronic key everyday  deactivate...             0  \n",
       "2      shame    construction go    look like   be...             0  \n",
       "3   foyer   mess  place  relax   bar     comforta...             0  \n",
       "4   room could     microwave  room   small leak  ...             0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3. Train - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"Category_Code\"]\n",
    "target_names = ['United Kingdom','United States of America', 'Australia', 'Ireland', 'United Arab Emirates','Saudi Arabia', 'Netherlands','Switzerland','Germany','Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Content_Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>room  nice   elderly  bite difficult   room  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>We had issues with our electronic key everyda...</td>\n",
       "      <td>issue   electronic key everyday  deactivate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>it s a shame about all the construction going...</td>\n",
       "      <td>shame    construction go    look like   be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Foyer was a mess Only place to relax was the ...</td>\n",
       "      <td>foyer   mess  place  relax   bar     comforta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Room could have done with a microwave our roo...</td>\n",
       "      <td>room could     microwave  room   small leak  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0            Australia   Rooms are nice but for elderly a bit difficul...   \n",
       "1            Australia   We had issues with our electronic key everyda...   \n",
       "2            Australia   it s a shame about all the construction going...   \n",
       "3            Australia   Foyer was a mess Only place to relax was the ...   \n",
       "4            Australia   Room could have done with a microwave our roo...   \n",
       "\n",
       "                                      Content_Parsed  \n",
       "0   room  nice   elderly  bite difficult   room  ...  \n",
       "1     issue   electronic key everyday  deactivate...  \n",
       "2      shame    construction go    look like   be...  \n",
       "3   foyer   mess  place  relax   bar     comforta...  \n",
       "4   room could     microwave  room   small leak  ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(\"Category_Code\", axis=1)\n",
    "feature_names = data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\jcaravella\\Documents\\Finalproject\\parsed.csv', index = False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Content_Parsed'], \n",
    "                                                    df['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154445, 300)\n",
      "(27255, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Australia' category:\n",
      "  . Most correlated unigrams:\n",
      ". wifi\n",
      ". bag\n",
      ". park\n",
      ". fridge\n",
      ". luggage\n",
      "  . Most correlated bigrams:\n",
      ". room little\n",
      ". air con\n",
      "\n",
      "# 'Canada' category:\n",
      "  . Most correlated unigrams:\n",
      ". street\n",
      ". bar\n",
      ". luggage\n",
      ". front\n",
      ". desk\n",
      "  . Most correlated bigrams:\n",
      ". air con\n",
      ". tea coffee\n",
      "\n",
      "# 'Germany' category:\n",
      "  . Most correlated unigrams:\n",
      ". windows\n",
      ". city\n",
      ". park\n",
      ". star\n",
      ". loud\n",
      "  . Most correlated bigrams:\n",
      ". tea coffee\n",
      ". star hotel\n",
      "\n",
      "# 'Ireland' category:\n",
      "  . Most correlated unigrams:\n",
      ". food\n",
      ". expensive\n",
      ". city\n",
      ". park\n",
      ". bar\n",
      "  . Most correlated bigrams:\n",
      ". room service\n",
      ". double bed\n",
      "\n",
      "# 'Netherlands' category:\n",
      "  . Most correlated unigrams:\n",
      ". something\n",
      ". tire\n",
      ". wifi\n",
      ". star\n",
      ". old\n",
      "  . Most correlated bigrams:\n",
      ". small room\n",
      ". star hotel\n",
      "\n",
      "# 'Saudi Arabia' category:\n",
      "  . Most correlated unigrams:\n",
      ". facilities\n",
      ". extremely\n",
      ". extra\n",
      ". experience\n",
      ". expect\n",
      "  . Most correlated bigrams:\n",
      ". double bed\n",
      ". would nice\n",
      "\n",
      "# 'Switzerland' category:\n",
      "  . Most correlated unigrams:\n",
      ". city\n",
      ". street\n",
      ". windows\n",
      ". old\n",
      ". star\n",
      "  . Most correlated bigrams:\n",
      ". tea coffee\n",
      ". star hotel\n",
      "\n",
      "# 'United Arab Emirates' category:\n",
      "  . Most correlated unigrams:\n",
      ". facilities\n",
      ". extremely\n",
      ". extra\n",
      ". experience\n",
      ". expect\n",
      "  . Most correlated bigrams:\n",
      ". double bed\n",
      ". would nice\n",
      "\n",
      "# 'United Kingdom' category:\n",
      "  . Most correlated unigrams:\n",
      ". facilities\n",
      ". extremely\n",
      ". extra\n",
      ". experience\n",
      ". expect\n",
      "  . Most correlated bigrams:\n",
      ". double bed\n",
      ". would nice\n",
      "\n",
      "# 'United States of America' category:\n",
      "  . Most correlated unigrams:\n",
      ". facilities\n",
      ". extremely\n",
      ". extra\n",
      ". experience\n",
      ". expect\n",
      "  . Most correlated bigrams:\n",
      ". double bed\n",
      ". would nice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Export what is needed for the next step\n",
    "with open('Pickles/X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "    \n",
    "# X_test    \n",
    "with open('Pickles/X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# y_train\n",
    "with open('Pickles/y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(y_train, output)\n",
    "    \n",
    "# y_test\n",
    "with open('Pickles/y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(y_test, output)\n",
    "    \n",
    "# df\n",
    "with open('Pickles/df.pickle', 'wb') as output:\n",
    "    pickle.dump(df, output)\n",
    "    \n",
    "# features_train\n",
    "with open('Pickles/features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('Pickles/labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('Pickles/features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "\n",
    "# labels_test\n",
    "with open('Pickles/labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('Pickles/tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
